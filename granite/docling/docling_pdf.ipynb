{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da06a2e",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Uncomment and run this only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af0d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdown\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: markdown\n",
      "Successfully installed markdown-3.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install docling\n",
    "%pip install markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ea1c32",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e152bd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/v8/xqs4lx991jv1sfdph64bb5bc0000gn/T/ipykernel_56400/1130344968.py\", line 1, in <module>\n",
      "    from docling.document_converter import DocumentConverter\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/docling/document_converter.py\", line 20, in <module>\n",
      "    from docling.backend.asciidoc_backend import AsciiDocBackend\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/docling/backend/asciidoc_backend.py\", line 20, in <module>\n",
      "    from docling.datamodel.base_models import InputFormat\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/docling/datamodel/base_models.py\", line 33, in <module>\n",
      "    from docling.datamodel.pipeline_options import PipelineOptions\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/docling/datamodel/pipeline_options.py\", line 15, in <module>\n",
      "    from docling.datamodel import asr_model_specs, vlm_model_specs\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/docling/datamodel/asr_model_specs.py\", line 9, in <module>\n",
      "    from docling.datamodel.pipeline_options_asr_model import (\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/docling/datamodel/pipeline_options_asr_model.py\", line 8, in <module>\n",
      "    from docling.datamodel.pipeline_options_vlm_model import (\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/docling/datamodel/pipeline_options_vlm_model.py\", line 6, in <module>\n",
      "    from transformers import StoppingCriteria\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/transformers/__init__.py\", line 27, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/transformers/utils/__init__.py\", line 24, in <module>\n",
      "    from .auto_docstring import (\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/transformers/utils/auto_docstring.py\", line 30, in <module>\n",
      "    from .generic import ModelOutput\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/transformers/utils/generic.py\", line 51, in <module>\n",
      "    import torch\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/emalaga/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3facbaef",
   "metadata": {},
   "source": [
    "## Analyzing the source\n",
    "\n",
    "First we set the source and parse it with docling's DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133d4241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 09:05:51,660 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-14 09:05:51,672 - INFO - Going to convert document batch...\n",
      "2025-11-14 09:05:51,673 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-11-14 09:05:51,677 - INFO - Auto OCR model selected ocrmac.\n",
      "2025-11-14 09:05:51,680 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-14 09:05:52,645 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-14 09:05:53,669 - INFO - Processing document 2408.09869v5.pdf\n",
      "2025-11-14 09:05:54,165 - ERROR - Stage layout failed for run 1: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.\n",
      "2025-11-14 09:05:55,264 - ERROR - Stage layout failed for run 1: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.\n",
      "2025-11-14 09:05:56,238 - ERROR - Stage layout failed for run 1: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.\n",
      "2025-11-14 09:05:59,062 - ERROR - Stage layout failed for run 1: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.\n",
      "2025-11-14 09:05:59,091 - INFO - Finished converting document 2408.09869v5.pdf in 8.67 sec.\n"
     ]
    },
    {
     "ename": "ConversionError",
     "evalue": "Conversion failed for: 2408.09869v5.pdf with status: ConversionStatus.FAILURE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConversionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m source = \u001b[33m\"\u001b[39m\u001b[33mhttps://arxiv.org/pdf/2408.09869\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m converter = DocumentConverter()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m doc = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m.document\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/docling/document_converter.py:237\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;129m@validate_call\u001b[39m(config=ConfigDict(strict=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    221\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     page_range: PageRange = DEFAULT_PAGE_RANGE,\n\u001b[32m    228\u001b[39m ) -> ConversionResult:\n\u001b[32m    229\u001b[39m     all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    230\u001b[39m         source=[source],\n\u001b[32m    231\u001b[39m         raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m         page_range=page_range,\n\u001b[32m    236\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/Box-Box/Personal/Coding Projects/Tutorials/.venv/lib/python3.11/site-packages/docling/document_converter.py:266\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    261\u001b[39m had_result = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raises_on_error \u001b[38;5;129;01mand\u001b[39;00m conv_res.status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m    263\u001b[39m     ConversionStatus.SUCCESS,\n\u001b[32m    264\u001b[39m     ConversionStatus.PARTIAL_SUCCESS,\n\u001b[32m    265\u001b[39m }:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ConversionError(\n\u001b[32m    267\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversion failed for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconv_res.input.file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconv_res.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m conv_res\n",
      "\u001b[31mConversionError\u001b[39m: Conversion failed for: 2408.09869v5.pdf with status: ConversionStatus.FAILURE"
     ]
    }
   ],
   "source": [
    "\n",
    "source = \"https://arxiv.org/pdf/2408.09869\"\n",
    "converter = DocumentConverter()\n",
    "doc = converter.convert(source).document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208b9476",
   "metadata": {},
   "source": [
    "Displaying the markdown representation of the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c387bc30",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Convert markdown to HTML and display in scrollable div\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmarkdown\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m markdown\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m html_content = markdown(\u001b[43mdoc\u001b[49m.export_to_markdown())\n\u001b[32m      7\u001b[39m display(HTML(\u001b[33mf\u001b[39m\u001b[33m'''\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m<div style=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmax-height: 600px; overflow-y: auto; border: 1px solid #ddd; padding: 10px;\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhtml_content\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33m</div>\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m'''\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Convert markdown to HTML and display in scrollable div\n",
    "from markdown import markdown\n",
    "html_content = markdown(doc.export_to_markdown())\n",
    "\n",
    "display(HTML(f'''\n",
    "<div style=\"max-height: 600px; overflow-y: auto; border: 1px solid #ddd; padding: 10px;\">\n",
    "    {html_content}\n",
    "</div>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72e310",
   "metadata": {},
   "source": [
    "## Creating a RAG application\n",
    "This section splits the text using the markdown headers, process it using an embeddling model and creates a FAISS vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "qiggybfrvfr",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:05:36,621 - INFO - Use pytorch device_name: mps\n",
      "2025-10-22 12:05:36,622 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 20 chunks\n"
     ]
    }
   ],
   "source": [
    "# Minimal RAG Application\n",
    "\n",
    "# 1. Get markdown content from the document\n",
    "markdown_content = doc.export_to_markdown()\n",
    "\n",
    "# 2. Split text by markdown headers\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(markdown_content)\n",
    "print(f\"Split into {len(md_header_splits)} chunks\")\n",
    "\n",
    "# 3. Create embeddings using HuggingFace model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 4. Create FAISS vector store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(md_header_splits, embeddings)\n",
    "\n",
    "# 5. Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 6. Set up the LLM\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"granite4:micro\")\n",
    "\n",
    "# 7. Create RAG chain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d89552c",
   "metadata": {},
   "source": [
    "Asking questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d89fc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:05:58,823 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What is this document about?\n",
      "\n",
      "Answer: This document describes a system called Docling that converts scanned PDF documents into structured data. The key points are:\n",
      "\n",
      "1. Docling uses a linear pipeline of operations to process each document sequentially.\n",
      "2. It first parses the PDF to extract text tokens and render bitmap images of each page.\n",
      "3. Then, it applies AI models on each page to extract features like layout and table structures.\n",
      "4. The results from all pages are aggregated and passed through a post-processing stage that augments metadata, detects language, infers reading order, and assembles a typed document object.\n",
      "5. Docling allows easy extension of the model library and pipelines for improving conversion quality and extracted metadata.\n",
      "\n",
      "In summary, this document is about an open-source system called Docling that converts scanned PDF documents into structured data using AI models, with plans to expand its capabilities in the future.\n"
     ]
    }
   ],
   "source": [
    "# 8. Test with a question\n",
    "question = \"What is this document about?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(f\"\\nQuestion: {question}\")\n",
    "print(f\"\\nAnswer: {result['result']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
